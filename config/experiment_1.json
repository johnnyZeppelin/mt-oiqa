{
  "training": {
    "lr": 5e-4,
    "batch_size": 8,
    "epochs": 400
  },
  "model": {
    "vmamba": {
      "depths": [3, 3, 27, 3],
      "dims": [128, 256, 512, 1024]
    }
  }
}